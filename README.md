# Real-Time Facial Emotion Detection with Adaptive Audio Feedback

A real-time system that detects a person's emotional state using facial expression
analysis and provides adaptive audio feedback. The system uses a camera to capture
facial expressions, applies computer vision and machine learning to classify emotions,
and responds with audio cues based on the detected emotional state.

> **Purpose**: Showcase how AI can recognize human emotions and respond in a supportive,
> non-intrusive way. This is **not** a medical or psychological treatment tool.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MAIN APPLICATION                     â”‚
â”‚                    (State Machine)                       â”‚
â”‚                                                         â”‚
â”‚  IDLE â†’ DETECTING â†’ SCANNING â†’ RESULT â†’ RESET â†’ IDLE   â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Camera  â”‚   Face   â”‚ Emotion  â”‚ Emotion  â”‚   Audio     â”‚
â”‚  Module  â”‚ Detector â”‚  Model   â”‚  Buffer  â”‚  Player     â”‚
â”‚          â”‚          â”‚  (CNN)   â”‚ (Vote)   â”‚ (pygame)    â”‚
â”‚ OpenCV   â”‚MediaPipe â”‚TensorFlowâ”‚ 3s windowâ”‚  .wav files â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
emotion_kiosk/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ emotion_model.h5        # CNN model (create with create_model.py)
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ happy.wav               # Generated audio cues
â”‚   â”œâ”€â”€ sad.wav
â”‚   â”œâ”€â”€ stressed.wav
â”‚   â””â”€â”€ neutral.wav
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ camera.py               # Webcam capture
â”‚   â”œâ”€â”€ face_detector.py        # MediaPipe face detection
â”‚   â”œâ”€â”€ emotion_model.py        # Emotion classification
â”‚   â”œâ”€â”€ emotion_buffer.py       # Temporal majority-vote buffer
â”‚   â”œâ”€â”€ audio_player.py         # Audio playback (pygame)
â”‚   â””â”€â”€ main.py                 # Main application (state machine + UI)
â”œâ”€â”€ create_model.py             # Generate model architecture
â”œâ”€â”€ generate_audio.py           # Generate audio .wav files
â”œâ”€â”€ train_model.py              # Train model on FER-2013 (bonus)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## Quick Start

### 1. Setup Environment

```bash
cd emotion_kiosk
python -m venv venv
venv\Scripts\activate           # Windows
# source venv/bin/activate      # macOS/Linux

pip install -r requirements.txt
```

### 2. Generate Assets

```bash
python generate_audio.py        # Creates audio/*.wav files
python create_model.py          # Creates models/emotion_model.h5
```

### 3. Run the Application

```bash
python src/main.py              # Normal mode
python src/main.py --demo       # Fullscreen demo/event mode
```

## Controls

| Key       | Action               |
|-----------|----------------------|
| **R**     | Reset / next user    |
| **F**     | Toggle fullscreen    |
| **Q/ESC** | Exit application     |

## Emotions Detected

| Emotion    | Audio Response              |
|------------|-----------------------------|
| ğŸ˜Š Happy   | Bright, upbeat tone         |
| ğŸ˜ Neutral | No audio                    |
| ğŸ˜¢ Sad     | Warm, comforting tone       |
| ğŸ˜° Stressed| Calm, soothing drone        |

## User Flow

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Idle Screen    â”‚  "Please stand in front of the camera"
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Face Detected  â”‚  Green bounding box appears
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Scanning (3s)  â”‚  "Scanning your expressionâ€¦" + progress bar
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Emotion Result â”‚  Shows emotion + plays audio (10-12s)
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Auto Reset     â”‚  "Next participant" â†’ returns to Idle
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Training a Real Model (Optional)

The included model has **random weights**. For real emotion detection:

1. Download the [FER-2013 dataset](https://www.kaggle.com/datasets/msambare/fer2013)
2. Organize into `data/train/` and `data/test/` with subfolders per emotion
3. Map FER-2013 labels: angry/disgust/fear â†’ stressed, surprise â†’ happy
4. Run training:

```bash
python train_model.py --data_dir data/ --epochs 50
```

## Key Design Decisions

- **Single face only**: Rejects frames with multiple faces to avoid confusion
- **3-second buffer**: Majority vote prevents emotion flickering
- **Offline operation**: No internet required â€” fast and reliable
- **FPS limiter (18 FPS)**: Prevents overheating during long sessions
- **Auto-reset**: Fully automated for exhibition/kiosk use

## Limitations

- Model accuracy depends on training data quality (untrained model = random)
- Performance varies with lighting conditions and face angles
- Not suitable for medical diagnosis or psychological assessment
- Works best with frontal face view at 0.5â€“2m distance
- Glasses and facial hair may affect detection confidence

## Technologies

- **OpenCV** â€” Camera capture and UI rendering
- **MediaPipe** â€” Real-time face detection
- **TensorFlow/Keras** â€” CNN emotion classification
- **pygame** â€” Audio playback
- **Python 3.8+** â€” Core language

---

*Built for public demonstration and educational purposes.*
